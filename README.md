# composite-damage-prediction
Surrogate model for generation of damage patterns on composite plates with cut-outs

# Contents of Repository
- data-generation
  - abaqus-models 
    > Generated Abaqus models including .inp files and .odb files, as well as README describing naming conventions
  - damage-patterns
    > Damage pattern images generated by processing .odb files
    - processed
      > Damage pattern images with borders trimmed, as well as README describing naming conventions
    - raw
      > Damage pattern images as generated by result_generator.py, as well as README describing naming conventions
    - process.m
      > Calls `RemoveWhiteSpace` on a batch of images and saves processed images in new folder
    - RemoveWhiteSpace.m
      > Trims borders of an image with padding
    - selectimagesforprocess.m
      > Determines which images in the directory have not been processed already and sends them to `process`
  - mesh_convergence.xls
    > Analysis of errors between successive FEM models to check for convergence of mesh
  - model_generator.py
    > To be attached as script in Abaqus to automate creation of Abaqus models (including .inp files) and subsequently writes to runfile
  - result_generator.py
    > To be attached as script in Abaqus to automate processing of .odb files and subsequently save damage patterns as images
  - runfile.txt
    > To be saved and run as .bat file after being modified by model_generator.py in order to generate .odb files from .inp files
- neural-network-models
  - convolutional
    > Convolutional neural network model (Python libraries, datasets and final weights not included in repo due to file size constraints)
    - tuning1
      > Training curves, predictions and log of hyperparameters used in first instance of training
    - tuning2
      > Training curves, predictions and log of hyperparameters used in second instance of training (with larger dataset)
    - cnn_architecture.py
      > Definitions of different CNN architecture variants
    - generate_data.py
      > Convert images into useable training, validation and test sets
    - helpers.py
      > Definitions of functions used in generate_data.py, cnn_architecture.py and main.py
    - main.py
      > Trains, validates and tests neural network
  - hybrid-mse
    > Hybrid neural network model based on the MSE loss function (Python libraries, datasets and final weights not included in repo due to file size constraints)
    - tuning
      > Training curves, predictions and log of hyperparameters used in training
    - CNN_Architecture.py
      > Definitions of different CNN architecture variants
    - generateData.py
      > Convert images into useable training, validation and test sets
    - helpers.py
      > Definitions of functions used in CNN_Architecture.py, generateData.py and index2index.py
    - input2index.py
      > Convert input parameters into autoencoder vector
  - hybrid-ssim
    > Hybrid neural network model based on the SSIM loss function (Python libraries, datasets and final weights not included in repo due to file size constraints)
    - tuning
      > Training curves, predictions and log of hyperparameters used in training
    - CNN_Architecture.py
      > Definitions of different CNN architecture variants
    - generateData.py
      > Convert images into useable training, validation and test sets
    - helpers.py
      > Definitions of functions used in CNN_Architecture.py, generateData.py and index2index_ssim.py
    - input2index_ssim.py
      > Convert input parameters into autoencoder vector
  - reduced-image
    > Reduced-image neural network model (Python libraries, datasets and final weights not included in repo due to file size constraints)
    - tuning
      > Training curves, predictions and log of hyperparameters used in training
    - CNN_Architecture.py
      > Definitions of different CNN architecture variants
    - generateData.py
      > Convert images into useable training, validation and test sets
    - helpers.py
      > Definitions of functions used in CNN_Architecture.py, generateData.py, index2index.py and splitNetwork.py
    - input2index.py
      > Convert input parameters into autoencoder vector
    - splitNetwork.py
      > Separate the convolution and deconvolution parts of the CNN
  - standard
    > Standard neural network model (Python libraries, datasets and final weights not included in repo due to file size constraints)
    - tuning1
      > Training curves, predictions and log of hyperparameters used in first instance of training
    - tuning2
      > Training curves, predictions and log of hyperparameters used in second instance of training (with larger dataset)
    - generate_data.py
      > Convert images into useable training, validation and test sets
    - helpers.py
      > Definitions of functions used in generate_data.py and main.py
    - main.py
      > Trains, validates and tests neural network
    - orig_dims.py
      > Original dimensions of images - used to convert predicted output into image
- LICENSE
- README.md
- thesis.pdf

# Reproduction Guidelines
This section describes how the results obtained in this work can be reproduced.

## Data Generation
1. Attach `model_generator.py` as a script in Abaqus - this populates `runfile.txt` with commands for the next step
1. Execute `runfile.txt` as a .bat script to generate .odb files for each FEM model
1. Attach `result_generator.py` as a script in Abaqus - this processes all the FEM models and saves the results as images
1. Run selectimagesforprocess.m using Matlab to 'clean' all images and prepare them for being used to train neural networks
